{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
<<<<<<< HEAD
  "cells": [
=======
>>>>>>> a730e4ebdbc12d1f068d5dab751e9c92c55c1708
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Preparations"
      ],
      "metadata": {
        "id": "MY7TKZ8qZ-65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "zp8MbHcKaON1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The necessary libraries for the project are downloaded and imported."
      ],
      "metadata": {
        "id": "DLwljtBUaScU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-recommenders --quiet\n",
        "!pip install -q --upgrade tensorflow-datasets --quiet"
      ],
      "metadata": {
        "id": "z_RDjWxra6hS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77724a9a-9b30-4fe9-9456-b2673dc1cf7f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/96.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from IPython.display import Markdown, display\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import tensorflow_recommenders as tfrs"
      ],
      "metadata": {
        "id": "_0DrjBEjUGgB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Datasets URLs"
      ],
      "metadata": {
        "id": "uZUcTjLobF3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset URLs used in the project are listed."
      ],
      "metadata": {
        "id": "oXB2R8qGbRxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "    \"https://raw.githubusercontent.com/AldiraPutri19/Locoveer/refs/heads/machine-learning/datasets/user_ratings.csv\",\n",
        "    \"https://raw.githubusercontent.com/AldiraPutri19/Locoveer/refs/heads/machine-learning/datasets/users.csv\",\n",
        "    \"https://raw.githubusercontent.com/AldiraPutri19/Locoveer/refs/heads/machine-learning/datasets/travel_destinations.csv\"\n",
        "]"
      ],
      "metadata": {
        "id": "nVILsGmwbRG0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Directory"
      ],
      "metadata": {
        "id": "OEJfznmEbXTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A directory is created to store the downloaded datasets."
      ],
      "metadata": {
        "id": "xOTOw8eVbcpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/\"\n",
        "os.makedirs(file_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "PcVh1xYAbe6s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and Load Dataset"
      ],
      "metadata": {
        "id": "y5lWqh8Hbvmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Function"
      ],
      "metadata": {
        "id": "wskj0roZbxa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function is defined to download files from the provided URLs and save them to the local directory."
      ],
      "metadata": {
        "id": "9RLzAH8sb0Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_data(url):\n",
        "    file_name = url.split(\"/\")[-1]\n",
        "    full_file_path = os.path.join(file_path, file_name)\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        with open(full_file_path, \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "            print(f\"Successfully downloaded: {file_name}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to download {file_name} - Error: {e}\")"
      ],
      "metadata": {
        "id": "_DCAE_gEcN0P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download All Datasets"
      ],
      "metadata": {
        "id": "O2HFoEzhb3sO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The datasets are downloaded in parallel using `ThreadPoolExecutor` to accelerate the download process.\n",
        "\n"
      ],
      "metadata": {
        "id": "aUlweNjyb6lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with ThreadPoolExecutor() as executor:\n",
        "    executor.map(download_data, urls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wL5c_76cPa1",
        "outputId": "f0dcb269-50d8-4fc2-ea23-f91bce6ef59c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded: users.csv\n",
            "Successfully downloaded: travel_destinations.csv\n",
            "Successfully downloaded: user_ratings.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Datasets"
      ],
      "metadata": {
        "id": "Rn3sAPNicFPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The downloaded CSV files are read into pandas DataFrames for further processing."
      ],
      "metadata": {
        "id": "Q0vmFzvDcIpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_rating = pd.read_csv('user_ratings.csv')\n",
        "user = pd.read_csv('users.csv')\n",
        "travel_destination = pd.read_csv('travel_destinations.csv')"
      ],
      "metadata": {
        "id": "rw9uvogkcSMI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration and Cleaning"
      ],
      "metadata": {
        "id": "54mlNdcVcZvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the Dataset"
      ],
      "metadata": {
        "id": "U38gK8QFcewW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A helper function is defined to display information about the dataset in markdown format for better readability."
      ],
      "metadata": {
        "id": "n-aNjMYWciLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "printmd(\"Dataset user:\")\n",
        "print(user.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "-LIVooJ9cha9",
        "outputId": "836474f7-5afd-4be3-d099-65308ddceead"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Dataset user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   User_ID             Name                          Email  Age  Gender  \\\n",
            "0        1     Tono Pratama     tonopratama858@example.com   34    Male   \n",
            "1        2       Eka Kusuma       ekakusuma629@example.com   59    Male   \n",
            "2        3   Lina Sari B.A.         linasari11@example.com   61  Female   \n",
            "3        4  Bambang Hidayat  bambanghidayat565@example.com   26  Female   \n",
            "4        5     Tono Santoso     tonosantoso978@example.com   49    Male   \n",
            "\n",
            "                       Address  \n",
            "0           Tegal, Jawa Tengah  \n",
            "1  Kupang, Nusa Tenggara Timur  \n",
            "2            Lhokseumawe, Aceh  \n",
            "3        Semarang, Jawa Tengah  \n",
            "4        Batam, Kepulauan Riau  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Statistics"
      ],
      "metadata": {
        "id": "QmPoIr_bclyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The script calculates and displays statistics, such as the number of unique users and destinations, and checks for missing values in the datasets."
      ],
      "metadata": {
        "id": "DmtfYTy_cnav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "printmd(\"Number of Users: {:,}\".format(len(user.User_ID.unique())))\n",
        "printmd(\"Number of Travel Destinations: {:,}\".format(len(travel_destination.Destination_ID.unique())))\n",
        "\n",
        "printmd(\"**Missing Values:**\")\n",
        "print(user.isnull().sum(), '\\n')\n",
        "print(user_rating.isnull().sum(), '\\n')\n",
        "print(travel_destination.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "jOjOHwUCcqd1",
        "outputId": "61c29e46-ac91-4115-d401-7a42f71d7764"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Number of Users: 1,000"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Number of Travel Destinations: 437"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Missing Values:**"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User_ID    0\n",
            "Name       0\n",
            "Email      0\n",
            "Age        0\n",
            "Gender     0\n",
            "Address    0\n",
            "dtype: int64 \n",
            "\n",
            "User_ID           0\n",
            "Destination_ID    0\n",
            "Rating            0\n",
            "dtype: int64 \n",
            "\n",
            "Destination_ID        0\n",
            "Destination_Name      0\n",
            "Description           0\n",
            "Category              0\n",
            "City                  0\n",
            "Price                 0\n",
            "Coordinate            0\n",
            "Lat                   3\n",
            "Long                  0\n",
            "Unnamed: 11         437\n",
            "Unnamed: 12           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "qietWt6vcq9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unnecessary columns in the travel destinations dataset are removed to simplify the data structure."
      ],
      "metadata": {
        "id": "OjwMz-dCct5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "travel_destination.drop(columns=['Coordinate', 'Lat', 'Long', 'Unnamed: 11', 'Unnamed: 12'], inplace=True)\n",
        "travel_destination.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIQtfReYcwlV",
        "outputId": "a1b19a8e-5b3d-42d3-e234-fef8ba370370"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 437 entries, 0 to 436\n",
            "Data columns (total 6 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Destination_ID    437 non-null    float64\n",
            " 1   Destination_Name  437 non-null    object \n",
            " 2   Description       437 non-null    object \n",
            " 3   Category          437 non-null    object \n",
            " 4   City              437 non-null    object \n",
            " 5   Price             437 non-null    float64\n",
            "dtypes: float64(2), object(4)\n",
            "memory usage: 20.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rating Analysis"
      ],
      "metadata": {
        "id": "_mv6aSfCcxPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The script computes the number of ratings and the average rating for each destination. Destinations with a number of ratings above a specified cutoff are selected."
      ],
      "metadata": {
        "id": "lG2z89tUcz45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_by_destination = user_rating.groupby(\"Destination_ID\").agg({\"User_ID\": \"count\", \"Rating\": \"mean\"}).reset_index()\n",
        "rating_by_destination.columns = [\"Destination_ID\", \"Number of Ratings\", \"Average Rating\"]\n",
        "\n",
        "cutoff = 50\n",
        "top_rated_destinations = rating_by_destination.loc[rating_by_destination[\"Number of Ratings\"] > cutoff].sort_values(by=\"Average Rating\", ascending=False)"
      ],
      "metadata": {
        "id": "ITj3wT5Qc2M_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "7j0TWeK8c2p7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter Data"
      ],
      "metadata": {
        "id": "RqICvUtoc7Us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ratings dataset is filtered to include only destinations that meet the criteria for the number of ratings."
      ],
      "metadata": {
        "id": "H87XwiiCc99S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recent_ratings = user_rating.loc[user_rating[\"Destination_ID\"].isin(top_rated_destinations[\"Destination_ID\"])]"
      ],
      "metadata": {
        "id": "AiJtTZ5qdAGp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Map IDs"
      ],
      "metadata": {
        "id": "-FfjqCo_dCQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "User and destination IDs are mapped to numeric values to facilitate embedding during modeling."
      ],
      "metadata": {
        "id": "7jiLFOpYdDnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "userIds = recent_ratings.User_ID.unique()\n",
        "destinationIds = recent_ratings.Destination_ID.unique()\n",
        "\n",
        "user_mapping = {id_: idx for idx, id_ in enumerate(userIds)}\n",
        "destination_mapping = {id_: idx for idx, id_ in enumerate(destinationIds)}\n",
        "\n",
        "recent_ratings['User_ID'] = recent_ratings['User_ID'].map(user_mapping)\n",
        "recent_ratings['Destination_ID'] = recent_ratings['Destination_ID'].map(destination_mapping)"
      ],
      "metadata": {
        "id": "y94e1udedHQM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow Dataset"
      ],
      "metadata": {
        "id": "9UfqArzIdIgY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A TensorFlow dataset is created from the filtered ratings data, preparing it for the training process."
      ],
      "metadata": {
        "id": "OwEIK7E2dL42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = tf.data.Dataset.from_tensor_slices({\n",
        "    \"userId\": tf.convert_to_tensor(recent_ratings.User_ID.astype(str).values, dtype=tf.string),\n",
        "    \"destinationId\": tf.convert_to_tensor(recent_ratings.Destination_ID.astype(str).values, dtype=tf.string),\n",
        "    \"rating\": tf.cast(recent_ratings.Rating.values, tf.float32),\n",
        "})"
      ],
      "metadata": {
        "id": "82FXkqsmdIE9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the Dataset"
      ],
      "metadata": {
        "id": "-3xIDfWKiCDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate the performance of the recommendation model, the data is split into three subsets:\n",
        "1. Training Set (70%): Used to train the model.\n",
        "2. Validation Set (15%): Used to tune hyperparameters and prevent overfitting.\n",
        "3. Test Set (15%): Used to evaluate the model's performance.\n",
        "\n",
        "The dataset is shuffled and then divided using TensorFlow’s `Dataset` API."
      ],
      "metadata": {
        "id": "fPGER07wiHNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_ratings = len(recent_ratings)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train_size = int(total_ratings * 0.7)\n",
        "val_size = int(total_ratings * 0.15)\n",
        "\n",
        "train = shuffled.take(train_size)\n",
        "validation = shuffled.skip(train_size).take(val_size)\n",
        "test = shuffled.skip(train_size + val_size).take(total_ratings - train_size - val_size)\n",
        "\n",
        "print(\"Training set size:\", train_size)\n",
        "print(\"Validation set size:\", val_size)\n",
        "print(\"Testing set size:\", total_ratings - train_size - val_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2cbBuqriahd",
        "outputId": "0c2b115b-b971-47f5-ce65-94fd29dc7f04"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 70000\n",
            "Validation set size: 15000\n",
            "Testing set size: 15000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "fXAgESrFdSAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ranking Model Definition"
      ],
      "metadata": {
        "id": "znKB0PvEdTVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function is defined to build a ranking model using embeddings for users and destinations. The embeddings are concatenated and passed through dense layers to predict ratings."
      ],
      "metadata": {
        "id": "Hd9CTDpKdWWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ranking_model(user_ids, destination_ids, embedding_dimension=128):\n",
        "    user_input = tf.keras.layers.Input(shape=(1,), name=\"userId\", dtype=tf.string)\n",
        "    user_lookup = tf.keras.layers.StringLookup(vocabulary=[str(x) for x in user_ids], mask_token=None)(user_input)\n",
        "    user_embedding = tf.keras.layers.Embedding(len(user_ids) + 1, embedding_dimension)(user_lookup)\n",
        "\n",
        "    destination_input = tf.keras.layers.Input(shape=(1,), name=\"destinationId\", dtype=tf.string)\n",
        "    destination_lookup = tf.keras.layers.StringLookup(vocabulary=[str(x) for x in destination_ids], mask_token=None)(destination_input)\n",
        "    destination_embedding = tf.keras.layers.Embedding(len(destination_ids) + 1, embedding_dimension)(destination_lookup)\n",
        "\n",
        "    concatenated = tf.keras.layers.concatenate([user_embedding, destination_embedding], axis=-1)\n",
        "\n",
        "    x = tf.keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01))(concatenated)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    output = tf.keras.layers.Dense(1, name=\"rating\")(x)\n",
        "\n",
        "    ranking_model = tf.keras.Model(inputs=[user_input, destination_input], outputs=output, name=\"RankingModel\")\n",
        "    return ranking_model"
      ],
      "metadata": {
        "id": "NA-xm8htdQwv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommendation Model"
      ],
      "metadata": {
        "id": "7w_y7OvmdZLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A custom recommendation model is implemented using `tensorflow_recommenders (tfrs)`. The model combines a ranking model with a task for predicting ratings."
      ],
      "metadata": {
        "id": "UndVWjRpddL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TravelRecommendationModel(tfrs.models.Model):\n",
        "    def __init__(self, ranking_model, **kwargs):\n",
        "        super(TravelRecommendationModel, self).__init__(**kwargs)\n",
        "        self.ranking_model = ranking_model\n",
        "        self.task = tfrs.tasks.Ranking(\n",
        "            loss=tf.keras.losses.MeanSquaredError(),\n",
        "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.ranking_model(inputs)\n",
        "\n",
        "    def compute_loss(self, features, training=False):\n",
        "        if isinstance(features, tuple):\n",
        "            features, labels = features\n",
        "        else:\n",
        "            labels = features.pop(\"rating\")\n",
        "        rating_predictions = self.ranking_model(features)\n",
        "        return self.task(labels=labels, predictions=rating_predictions)"
      ],
      "metadata": {
        "id": "Yebp7tpkdhI2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compiling The Model"
      ],
      "metadata": {
        "id": "UnmbNn4chMmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is compiled using the Adam optimizer and a learning rate of 0.001."
      ],
      "metadata": {
        "id": "-6XZdxxei2Te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dimension = 128\n",
        "ranking_model = create_ranking_model(userIds, destinationIds, embedding_dimension)\n",
        "travel_model = TravelRecommendationModel(ranking_model)\n",
        "\n",
        "travel_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))"
      ],
      "metadata": {
        "id": "AsPD2bOChUsi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "8V2UFIYFdkGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is trained on the prepared TensorFlow dataset, with early stopping implemented to prevent overfitting."
      ],
      "metadata": {
        "id": "npufBF2Gdlx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = travel_model.fit(\n",
        "    train.map(lambda x: ({\"userId\": x[\"userId\"], \"destinationId\": x[\"destinationId\"]}, x[\"rating\"])).shuffle(100_000).batch(2048).cache(),\n",
        "    validation_data=validation.map(lambda x: ({\"userId\": x[\"userId\"], \"destinationId\": x[\"destinationId\"]}, x[\"rating\"])).batch(1024).cache(),\n",
        "    epochs=20,\n",
        "    # callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snfa3SITdok4",
        "outputId": "d7414f42-788a-4783-af8a-9a1ef321addf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - loss: 3.8055 - regularization_loss: 2.4059 - root_mean_squared_error: 2.4391 - total_loss: 6.2114 - val_loss: 1.9949 - val_regularization_loss: 1.6955 - val_root_mean_squared_error: 1.4367 - val_total_loss: 3.6903\n",
            "Epoch 2/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 2.0149 - regularization_loss: 1.2723 - root_mean_squared_error: 1.4250 - total_loss: 3.2873 - val_loss: 1.9162 - val_regularization_loss: 0.9387 - val_root_mean_squared_error: 1.4089 - val_total_loss: 2.8550\n",
            "Epoch 3/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 2.0015 - regularization_loss: 0.7431 - root_mean_squared_error: 1.4149 - total_loss: 2.7447 - val_loss: 1.9152 - val_regularization_loss: 0.5876 - val_root_mean_squared_error: 1.4085 - val_total_loss: 2.5028\n",
            "Epoch 4/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 2.0015 - regularization_loss: 0.4866 - root_mean_squared_error: 1.4150 - total_loss: 2.4882 - val_loss: 1.9148 - val_regularization_loss: 0.4014 - val_root_mean_squared_error: 1.4087 - val_total_loss: 2.3163\n",
            "Epoch 5/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 2.0017 - regularization_loss: 0.3392 - root_mean_squared_error: 1.4154 - total_loss: 2.3409 - val_loss: 1.9155 - val_regularization_loss: 0.2848 - val_root_mean_squared_error: 1.4090 - val_total_loss: 2.2003\n",
            "Epoch 6/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 2.0017 - regularization_loss: 0.2424 - root_mean_squared_error: 1.4153 - total_loss: 2.2441 - val_loss: 1.9183 - val_regularization_loss: 0.2047 - val_root_mean_squared_error: 1.4101 - val_total_loss: 2.1230\n",
            "Epoch 7/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 2.0021 - regularization_loss: 0.1749 - root_mean_squared_error: 1.4159 - total_loss: 2.1770 - val_loss: 1.9249 - val_regularization_loss: 0.1482 - val_root_mean_squared_error: 1.4125 - val_total_loss: 2.0731\n",
            "Epoch 8/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 2.0030 - regularization_loss: 0.1270 - root_mean_squared_error: 1.4164 - total_loss: 2.1300 - val_loss: 1.9239 - val_regularization_loss: 0.1080 - val_root_mean_squared_error: 1.4122 - val_total_loss: 2.0319\n",
            "Epoch 9/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 2.0041 - regularization_loss: 0.0926 - root_mean_squared_error: 1.4167 - total_loss: 2.0968 - val_loss: 1.9265 - val_regularization_loss: 0.0791 - val_root_mean_squared_error: 1.4131 - val_total_loss: 2.0056\n",
            "Epoch 10/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 2.0047 - regularization_loss: 0.0680 - root_mean_squared_error: 1.4171 - total_loss: 2.0727 - val_loss: 1.9257 - val_regularization_loss: 0.0582 - val_root_mean_squared_error: 1.4128 - val_total_loss: 1.9839\n",
            "Epoch 11/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 2.0045 - regularization_loss: 0.0502 - root_mean_squared_error: 1.4170 - total_loss: 2.0547 - val_loss: 1.9265 - val_regularization_loss: 0.0430 - val_root_mean_squared_error: 1.4132 - val_total_loss: 1.9696\n",
            "Epoch 12/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 2.0043 - regularization_loss: 0.0371 - root_mean_squared_error: 1.4170 - total_loss: 2.0414 - val_loss: 1.9234 - val_regularization_loss: 0.0320 - val_root_mean_squared_error: 1.4120 - val_total_loss: 1.9554\n",
            "Epoch 13/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 2.0035 - regularization_loss: 0.0277 - root_mean_squared_error: 1.4166 - total_loss: 2.0312 - val_loss: 1.9221 - val_regularization_loss: 0.0239 - val_root_mean_squared_error: 1.4116 - val_total_loss: 1.9461\n",
            "Epoch 14/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 2.0031 - regularization_loss: 0.0207 - root_mean_squared_error: 1.4164 - total_loss: 2.0239 - val_loss: 1.9214 - val_regularization_loss: 0.0179 - val_root_mean_squared_error: 1.4113 - val_total_loss: 1.9393\n",
            "Epoch 15/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 2.0031 - regularization_loss: 0.0156 - root_mean_squared_error: 1.4163 - total_loss: 2.0187 - val_loss: 1.9209 - val_regularization_loss: 0.0136 - val_root_mean_squared_error: 1.4112 - val_total_loss: 1.9345\n",
            "Epoch 16/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 2.0029 - regularization_loss: 0.0118 - root_mean_squared_error: 1.4163 - total_loss: 2.0147 - val_loss: 1.9222 - val_regularization_loss: 0.0103 - val_root_mean_squared_error: 1.4116 - val_total_loss: 1.9325\n",
            "Epoch 17/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 2.0031 - regularization_loss: 0.0090 - root_mean_squared_error: 1.4164 - total_loss: 2.0121 - val_loss: 1.9211 - val_regularization_loss: 0.0079 - val_root_mean_squared_error: 1.4112 - val_total_loss: 1.9290\n",
            "Epoch 18/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 2.0027 - regularization_loss: 0.0069 - root_mean_squared_error: 1.4162 - total_loss: 2.0096 - val_loss: 1.9206 - val_regularization_loss: 0.0061 - val_root_mean_squared_error: 1.4111 - val_total_loss: 1.9267\n",
            "Epoch 19/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 2.0023 - regularization_loss: 0.0053 - root_mean_squared_error: 1.4161 - total_loss: 2.0077 - val_loss: 1.9209 - val_regularization_loss: 0.0047 - val_root_mean_squared_error: 1.4112 - val_total_loss: 1.9257\n",
            "Epoch 20/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 2.0022 - regularization_loss: 0.0041 - root_mean_squared_error: 1.4161 - total_loss: 2.0064 - val_loss: 1.9217 - val_regularization_loss: 0.0037 - val_root_mean_squared_error: 1.4115 - val_total_loss: 1.9254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation and Model Saving"
      ],
      "metadata": {
        "id": "d3aCkOXKdpUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Model"
      ],
      "metadata": {
        "id": "8tTN0RNGd8yB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's performance is evaluated on the test dataset, and the results are displayed."
      ],
      "metadata": {
        "id": "w1AONZ_peA-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_data):\n",
        "    cached_test = test_data.batch(1024).cache()\n",
        "    return model.evaluate(cached_test, return_dict=True)\n",
        "\n",
        "# Example evaluation:\n",
        "test_results = evaluate_model(travel_model, test)\n",
        "print(\"Test Results:\", test_results)"
      ],
      "metadata": {
        "id": "fiuXKMd2eDni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c96b8c-eb45-481f-f6af-18f348e821d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.0168 - regularization_loss: 0.0037 - root_mean_squared_error: 1.4241 - total_loss: 2.0205\n",
            "Test Results: {'loss': 1.923867106437683, 'regularization_loss': 0.00365427671931684, 'root_mean_squared_error': 1.4231739044189453, 'total_loss': 1.9275213479995728}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapping the Model"
      ],
      "metadata": {
        "id": "7qnKWgoudr8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trained model is wrapped in a functional model structure with explicit inputs and outputs for easier integration and deployment."
      ],
      "metadata": {
        "id": "fFxoL6eNdyK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"userId\": tf.keras.layers.Input(name=\"userId\", shape=(), dtype=tf.string),\n",
        "    \"destinationId\": tf.keras.layers.Input(name=\"destinationId\", shape=(), dtype=tf.string),\n",
        "}\n",
        "outputs = travel_model(inputs)\n",
        "wrapped_model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "Cjh9h3idd0n-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save and Download the Model"
      ],
      "metadata": {
        "id": "tsU5QUO9d1Vz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The wrapped model is saved and downloaded to disk for future use."
      ],
      "metadata": {
        "id": "sCNA6dEJd44I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wrapped_model.save('collaborative_filtering_recommendation_system.keras')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('collaborative_filtering_recommendation_system.keras')"
      ],
      "metadata": {
        "id": "AXj1jzX6d8Oz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c3e8ea7c-a871-4b15-b636-9f4ee30a015f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c7b3fb4a-9905-46e2-8ffa-29166c5d7349\", \"collaborative_filtering_recommendation_system.keras\", 5817189)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating and Displaying Recommendations"
      ],
      "metadata": {
        "id": "L8DJ7k2FgMnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model is trained and evaluated, it can be used to generate personalized recommendations for users. The `generate_recommendations` function takes a user ID and a list of destination IDs, then ranks the destinations based on predicted ratings."
      ],
      "metadata": {
        "id": "026gsvwCgzUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recommendations(model, user_id, destination_ids, user_mapping, travel_destination, top_n=10):\n",
        "    test_rating = {}\n",
        "\n",
        "    for m in destination_ids:\n",
        "        test_rating[m] = model.ranking_model(\n",
        "            {\"userId\": tf.convert_to_tensor([user_id], dtype=tf.string)},\n",
        "            {\"destinationId\": tf.convert_to_tensor([m], dtype=tf.string)}\n",
        "        )\n",
        "\n",
        "    top_destinations = sorted(test_rating, key=test_rating.get, reverse=True)[:top_n]\n",
        "\n",
        "    recommendations = []\n",
        "    for dest_id in top_destinations:\n",
        "        dest_name = travel_destination[travel_destination[\"Destination_ID\"] == dest_id][\"Destination_Name\"].iloc[0]\n",
        "        recommendations.append(dest_name)\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "user_rand = userIds[123]\n",
        "test_rating = {}\n",
        "for m in test.take(10):\n",
        "    test_rating[m[\"destinationId\"].numpy()] = ranking_model(\n",
        "        {\"userId\": tf.convert_to_tensor([str(user_rand)], dtype=tf.string),\n",
        "         \"destinationId\": tf.convert_to_tensor([str(m[\"destinationId\"].numpy())], dtype=tf.string)}\n",
        "    )\n",
        "\n",
        "print(\"Top 10 recommended travel destinations for User {}: \".format(user_rand))\n",
        "for m in sorted(test_rating, key=test_rating.get, reverse=True):\n",
        "    dest_id = int(m)\n",
        "\n",
        "    dest_name = travel_destination[travel_destination[\"Destination_ID\"] == dest_id][\"Destination_Name\"].iloc[0]\n",
        "    user_name = user[user[\"User_ID\"] == user_rand][\"Name\"].iloc[0]\n",
        "\n",
        "    print(f\"User: {user_name}, Destination: {dest_name} (ID: {dest_id})\")"
      ],
      "metadata": {
        "id": "z49kfbKygvZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f13fd325-f183-4c4a-fb69-831180094ffa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 recommended travel destinations for User 181: \n",
            "User: Sukmono Hidayat, Destination: Taman Tabanas (ID: 383)\n",
            "User: Sukmono Hidayat, Destination: Desa Wisata Lembah Kalipancur (ID: 340)\n",
            "User: Sukmono Hidayat, Destination: Curug Cipanas (ID: 275)\n",
            "User: Sukmono Hidayat, Destination: Kebun Bibit Wonorejo (ID: 406)\n",
            "User: Sukmono Hidayat, Destination: Geoforest Watu Payung Turunan (ID: 167)\n",
            "User: Sukmono Hidayat, Destination: Curug Bugbrug (ID: 273)\n",
            "User: Sukmono Hidayat, Destination: Taman Kupu-Kupu Cihanjuang (ID: 326)\n",
            "User: Sukmono Hidayat, Destination: Masjid Istiqlal (ID: 22)\n",
            "User: Sukmono Hidayat, Destination: La Kana Chapel (ID: 377)\n",
            "User: Sukmono Hidayat, Destination: Puncak Kebun Buah Mangunan (ID: 133)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vKsM_J6ppq7I"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}
